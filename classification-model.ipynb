{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ee6eb3",
   "metadata": {},
   "source": [
    "## Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e331f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5ff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"D:\\\\Education\\\\IIT\\\\3rd yr\\\\Edge AI - CM 3606\\\\EdgeAI - CW - git\\\\garbage-classifier\\\\Dataset\\\\train\"\n",
    "validation_dir = r\"D:\\\\Education\\\\IIT\\\\3rd yr\\\\Edge AI - CM 3606\\\\EdgeAI - CW - git\\\\garbage-classifier\\\\Dataset\\\\validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d55eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing images\n",
    "IMG_SHAPE = (224, 224)\n",
    "\n",
    "data_gen_train = ImageDataGenerator(\n",
    "  rescale=1/255., # Normalize the pixel values to the range between 0-1\n",
    "  rotation_range=40,  # Randomly rotate images up to 40 degrees\n",
    "  width_shift_range=0.2,  # Randomly shifts images horizontally by 20% of the width\n",
    "  height_shift_range=0.2, # Randomly shifts images vertically by 20% of the height\n",
    "  shear_range=0.2,  # Random shearing transformation\n",
    "  zoom_range=0.2, # Randomly zoom in on images\n",
    "  horizontal_flip=True, # Randomly flip  images horizontally\n",
    "  fill_mode='nearest' # Fill in new pixels created by transformation using the nearest pixel values\n",
    ")\n",
    "data_gen_valid = ImageDataGenerator(rescale=1/255.) # Validation data\n",
    "\n",
    "# Seperate generators for training and validation data\n",
    "train_generator = data_gen_train. flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size=IMG_SHAPE, \n",
    "    batch_size=32, \n",
    "    class_mode=\"categorical\") # Generate batched of augmented image data directly from training & validation directories.. Class mode is categorical since we have 3 classes (Plastic, Metal, Cardboard)\n",
    "valid_generator = data_gen_valid. flow_from_directory(\n",
    "    validation_dir, \n",
    "    target_size=IMG_SHAPE, \n",
    "    batch_size=32, \n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad5e975",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to count images per class\n",
    "def count_images_per_class(generator):\n",
    "    class_counts = {class_name: 0 for class_name in generator.class_indices.keys()}\n",
    "    for file_path, class_idx in zip(generator.filepaths, generator.classes):\n",
    "        class_name = list(generator.class_indices.keys())[list(generator.class_indices.values()).index(class_idx)]\n",
    "        class_counts[class_name] += 1\n",
    "    return class_counts\n",
    "\n",
    "# Count for training and validation sets\n",
    "train_counts = count_images_per_class(train_generator)\n",
    "val_counts = count_images_per_class(valid_generator)\n",
    "\n",
    "# Combine counts into one dict for full dataset\n",
    "total_counts = {cls: train_counts.get(cls, 0) + val_counts.get(cls, 0) for cls in train_counts.keys()}\n",
    "\n",
    "# Plotting\n",
    "classes = list(total_counts.keys())\n",
    "counts = list(total_counts.values())\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(classes, counts, color=['skyblue', 'salmon', 'limegreen'])\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.title(\"Image Distribution per Class (Train + Validation)\")\n",
    "\n",
    "# Add counts on top of bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 10, int(yval), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b771a4c8",
   "metadata": {},
   "source": [
    "## Load the pre-trained MobileNetV2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MobileNetV2 model\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE + (3,), include_top=False, weights=\"imagenet\")\n",
    "base_model. summary ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3c15fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the base model\n",
    "base_model.trainable = False # Freeze all the layers in the base model. This prevents their weights from being updated during training which helps retain the pretrained features learned from the imagenet dataset. This allows to focus on training the custom head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cdf0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom head specific to binary classification task of distinguishing between cat and dogs\n",
    "model = tf.keras.models. Sequential( [  # Use sequential method to create a new model by stacking layers sequentially.This make it easy to add layers on top of the pre trained base model.\n",
    "    base_model, # First layer of the new model is the base model which is the Frozen MobilenetV2 Model\n",
    "    tf.keras. layers.GlobalAveragePooling2D(),  # This layer reduces each feature map to a single value by taking the average effectively flattening the output of the convolutional base model. It helps to reduce number of parameters & prevents overfitting.\n",
    "    tf.keras.layers.Dropout(0.2), # Dropout is aregularization technique that randomly sets 20% of the input units to zero during training. This helps to prevent overfitting by making the model more robust.\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # Output layer with 3 units (for 3 classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98883de7",
   "metadata": {},
   "source": [
    "## Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02151d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6584c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model. fit(train_generator, epochs=25, validation_data=valid_generator)  # This invloves Feeding it to training data & validating its performance on the validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d0958",
   "metadata": {},
   "source": [
    "## Track & Display Best Epoch Based on Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b291eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "best_epoch = np.argmax(val_acc) + 1\n",
    "best_val_acc = val_acc[best_epoch - 1]\n",
    "print(f\"Best Epoch: {best_epoch}, Best Validation Accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea3a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc, val_top3_acc = model.evaluate(valid_generator)\n",
    "print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "print(f'Validation Top-3 Accuracy: {val_top3_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196c8fc",
   "metadata": {},
   "source": [
    "## Plot Training & Validation Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb16f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.scatter(best_epoch, best_val_acc, color='red', label='Best Epoch')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee68cd",
   "metadata": {},
   "source": [
    "## Class-wise Accuracy (Confusion Matrix & Classification Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a641c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Get class labels\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Predict\n",
    "Y_pred = model.predict(valid_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = valid_generator.classes\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Confusion Matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0248",
   "metadata": {},
   "source": [
    "## Transfer learning model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3342815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save((\"Model Experiments/fine-tuning-garbage-classifier-25\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f397a31",
   "metadata": {},
   "source": [
    "## Fine-tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dac9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model. trainable = True  # Make entire base model trainable\n",
    "fine_tune_at = 100  # Finetune the model from layer 100 onwords keeping the first 100 layers frozen to preserve the learned features\n",
    "\n",
    "for layer in base_model. layers[: fine_tune_at] :\n",
    "  layer. trainable = False  # This ensure only the layers after the 100th layer are updated during fine tuning\n",
    "\n",
    "#After unfreezing some layers we recompile the model\n",
    "\n",
    "# Recompile the model for fine-tuning with a lower learning rate - Lower lr is crucial for finetuning as it allows the model to make more precise updates to the weights without drastically changing them\n",
    "model. compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), \n",
    "  loss='categorical_crossentropy', \n",
    "  # metrics=['accuracy']\n",
    "  metrics=['accuracy', tf.keras.metrics.TopKCategoricalAccuracy(k=3)]\n",
    "  )\n",
    "\n",
    "# Finally call the fit method again to train the model - but this time with the some layers of the base model unfrozen. We use the same training and validation generators\n",
    "\n",
    "# Fine-tune the model\n",
    "history_fine = model. fit(train_generator, epochs=25, validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642fe822",
   "metadata": {},
   "source": [
    "## Track & Display Best Epoch Based on Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d11edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "val_acc = history_fine.history['val_accuracy']\n",
    "best_epoch = np.argmax(val_acc) + 1\n",
    "best_val_acc = val_acc[best_epoch - 1]\n",
    "print(f\"Best Epoch: {best_epoch}, Best Validation Accuracy: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fc0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc, val_top3_acc = model.evaluate(valid_generator)\n",
    "print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "print(f'Validation Top-3 Accuracy: {val_top3_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85c363",
   "metadata": {},
   "source": [
    "## Plot Training & Validation Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90778270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_fine.history['accuracy']\n",
    "val_acc = history_fine.history['val_accuracy']\n",
    "loss = history_fine.history['loss']\n",
    "val_loss = history_fine.history['val_loss']\n",
    "epochs_range = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.scatter(best_epoch, best_val_acc, color='red', label='Best Epoch')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a7ec0",
   "metadata": {},
   "source": [
    "## Class-wise Accuracy (Confusion Matrix & Classification Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Get class labels\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Predict\n",
    "Y_pred = model.predict(valid_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_true = valid_generator.classes\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Confusion Matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e68068",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Model Experiments/fine-tuning-garbage-classifier-25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8665ae",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
